{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bermanlabemory/gait_signatures/blob/main/Gait_Signatures_Script_4_Short_TimeSelf_Driven_Signatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This script computes the short-time self-driven signatures\n",
        "Short-time self-driven gait signatures by integrating the model forward in time on full gait cycle, initialized from the internal and kinematic states at the start of the gait cycle.\n",
        "____________\n",
        "____________\n",
        "**NOTE**: This file was ONLY used to select model hyperparameters and generate supplementary figures.\n",
        "\n",
        "First, Scripts 1-3 must be run to generate the models that are analyzed here.\n",
        "____________\n",
        "____________\n",
        "**Steps:** \n",
        "1. Load RNN dynamics model\n",
        "2. Load phase-averaged externally-signatures\n",
        "3. Load phase esimates and gait kinematics\n",
        "3. Idenitfy initial conditions for simulations: the start of each cycle and extract kinematic and internal states. \n",
        "____________\n",
        "4. Using the above initial conditions integrate the model forward in time 1 stride \n",
        "  6. Compute error relative to externally-driven prediction\n",
        "5. Average errors across strides for each trial  \n",
        "8. Take average & SD error across trials\n",
        "\n",
        "____________\n",
        "____________\n",
        "\n",
        "**Created by**: Michael C. Rosenberg\n",
        "\n",
        "**Date**: 09/22/22"
      ],
      "metadata": {
        "id": "onLC9Msr6_RX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 0**: Mount (connect to) your google drive folder where you want to save the simulation results and model parameters."
      ],
      "metadata": {
        "id": "kLBAyLXe7udu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "Iuzkec-P1z7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b97ad8-1043-4ad7-c7f7-960ff3d454a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check python version \n",
        "from platform import python_version\n",
        "print(python_version())\n",
        "\n",
        "# check tensorflow version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# Check memory\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfiYeSIR702R",
        "outputId": "178505d0-a502-4a5e-8f8c-9d015bf5c54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1**: Import necessary packages and functions to develop model"
      ],
      "metadata": {
        "id": "WDY0A5Qa77-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.python.keras.layers.recurrent import LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.model_selection as model_selection\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import keras as k\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from copy import copy\n",
        "import scipy.io\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "from scipy import interpolate\n",
        "from numpy import sin,cos,pi,array,linspace,cumsum,asarray,dot,ones\n",
        "from pylab import plot, legend, axis, show, randint, randn, std,lstsq\n",
        "\n",
        "from sklearn.manifold import MDS\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm "
      ],
      "metadata": {
        "id": "Sjnyu-Hi70_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/NeuromechanicsLab/GaitSignatures/\n",
        "\n",
        "\n",
        "# Ensure fourierseries.py is in the pathway\n",
        "!ls -l fourierseries.py"
      ],
      "metadata": {
        "id": "ZMRQ1Zrk_5m9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8224e9c-489e-4c7e-da47-e24af5314ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/NeuromechanicsLab/GaitSignatures\n",
            "-rw------- 1 root root 7259 May 29  2020 fourierseries.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Phaser wrapper to estimate system phase\n",
        "import fourierseries\n",
        "import util\n",
        "import phaser\n",
        "import dataloader\n",
        "# Preprocess data for a single subject - to be send to modeling frameworks\n",
        "def find_phase(k):\n",
        "    \"\"\"\n",
        "    Detrend and compute the phase estimate using Phaser\n",
        "    INPUT:\n",
        "      k -- dataframe\n",
        "    OUTPUT:\n",
        "      k -- dataframe\n",
        "    \"\"\"\n",
        "    #l = ['hip_flexion_l','hip_flexion_r'] # Phase variables = hip flexion angles\n",
        "    y = np.array(k)\n",
        "    print(y.shape)\n",
        "    y = util.detrend(y.T).T\n",
        "    print(y.shape)\n",
        "    phsr = phaser.Phaser(y=y)\n",
        "    k[:] = phsr.phaserEval(y)[0,:]\n",
        "    return k"
      ],
      "metadata": {
        "id": "956M3pr8_56k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Load module in Google Drive"
      ],
      "metadata": {
        "id": "g4J5BZIg8EYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The path to save the models and read data from\n",
        "path = '/content/drive/My Drive/NeuromechanicsLab/GaitSignatures/'\n",
        "\n",
        "# Insert the directory\n",
        "import sys\n",
        "sys.path.insert(0,path)"
      ],
      "metadata": {
        "id": "8PRNNDCI71CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3**: Load in data and specify variables/parameters"
      ],
      "metadata": {
        "id": "DAhc9QkW8ONR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-changing variables \n",
        "\n",
        "# number of trials in dataset \n",
        "trialnum = 72 # 72 total trials\n",
        "\n",
        "# number of samples in each trial\n",
        "trialsamp = 1500\n",
        "\n",
        "# number of features collected per trial\n",
        "feats = 6\n",
        "\n",
        "#Batch size - same as the number of traintrials\n",
        "batch_size = trialnum\n",
        "\n",
        "# Number of Layers\n",
        "numlayers = 1\n",
        "\n",
        "# Choose the number of iterations to train the model- if this script has been run previously enter a value greater than was \n",
        "# inputted before and rerun the script. \n",
        "finalepoch = 10000\n",
        "\n",
        "# load the input data/kinematics\n",
        "datafilepath = path + 'PareticvsNonP_RNNData.csv' #input data\n",
        "all_csvnp = np.loadtxt(datafilepath,delimiter=',').T\n",
        "\n",
        "# reshape all the input data into a tensor\n",
        "all_inputdata_s = all_csvnp.reshape(trialnum,trialsamp,feats) \n",
        "csvnp = all_inputdata_s\n",
        "print('original input data shape is: '+ str(all_csvnp.shape ))\n",
        "print('input data reshaped is: '+ str(all_inputdata_s.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXEEUgWB8Mk0",
        "outputId": "350d841e-c3bf-4b25-c4cb-9f5847c1643f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original input data shape is: (108000, 6)\n",
            "input data reshaped is: (72, 1500, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4**: Develop list of model architectures and corresponding variables to train. This step also generates list of folder names and pathways where the models will be saved and accessed later."
      ],
      "metadata": {
        "id": "q_A7pitQ8XS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a list of models and corresponding parameters to test \n",
        "test_model_nodes = [128, 256,512,1024] \n",
        "seqs = [249,499,749] #lookback parameter\n",
        "\n",
        "test_model_nodes = [ 512] \n",
        "seqs = [499] #lookback parameter\n",
        "\n",
        "# run multiple model architechtures many times to test stability of cost function outputs\n",
        "runs = 1 # Number of times to train recurrent neural network (RNN) models, starting from random initial conditions. We used this for hyperparameter selection\n",
        "test_model_seq = np.repeat(seqs, runs) # Specify each model's hyperparameters\n",
        "\n",
        "count = np.arange(runs)\n",
        "\n",
        "All_nodes = np.empty([0,1], dtype='int')\n",
        "All_seq = np.empty([0,1],dtype='int')\n",
        "All_valseg = np.empty([0,1],dtype='int')\n",
        "All_trainseg = np.empty([0,1],dtype='int')\n",
        "All_modelname = []\n",
        "All_mod_name = []\n",
        "count = np.empty([0,1],dtype='int'); #initialize model run -- this serves as the model run ID number\n",
        "ct = 0\n",
        "for a in test_model_nodes:\n",
        "  for b in test_model_seq:\n",
        "    count = np.append(count,  ct + 1 )\n",
        "    #if statement for valseg, trainseg based on sequence length\n",
        "    if int(b) == 249:\n",
        "      trainseg = 4\n",
        "      valseg = 2\n",
        "    elif int(b) == 499: \n",
        "      trainseg = 2\n",
        "      valseg = 1\n",
        "    elif int(b) == 749:\n",
        "      trainseg = 1\n",
        "      valseg = 1\n",
        "\n",
        "    # Store resulting model structures and training plans\n",
        "    All_nodes = np.append(All_nodes, a) \n",
        "    All_seq = np.append(All_seq, int(b))\n",
        "    All_valseg = np.append(All_valseg, valseg)\n",
        "    All_trainseg = np.append(All_trainseg, trainseg)\n",
        "    All_modelname = np.append(All_modelname, 'UNIT_' + str(a) + '_LB_' + str(b) + '_run_' + str(count[-1]) + '/' )\n",
        "    All_mod_name = np.append(All_mod_name, 'UNIT_' + str(a) + '_LB_' + str(b) + '_run_' + str(count[-1]) )\n",
        "\n",
        "    if ct+1 < runs:\n",
        "      ct += 1\n",
        "    else:\n",
        "      ct = 0"
      ],
      "metadata": {
        "id": "vAN8l21V8ZeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95907080-dc7b-4693-dcd9-b39d5f4b5d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['UNIT_512_LB_499_run_1' 'UNIT_512_LB_499_run_2' 'UNIT_512_LB_499_run_3'\n",
            " 'UNIT_512_LB_499_run_4' 'UNIT_512_LB_499_run_5' 'UNIT_512_LB_499_run_6'\n",
            " 'UNIT_512_LB_499_run_7' 'UNIT_512_LB_499_run_8' 'UNIT_512_LB_499_run_9'\n",
            " 'UNIT_512_LB_499_run_10']\n",
            "/content/drive/My Drive/NeuromechanicsLab/GaitSignatures/UNIT_512_LB_499_run_1/UNIT_512_LB_499_run_1_bestwhole.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5**: Generate self-driven short-time gait singatures\n",
        "\n",
        "1. Load trained model architectures in loop\n",
        "2. Load phase estimates for the corresponding long-term predictions\n",
        "3. Load ext. driven H & C values\n",
        "3. Find cycle trainsitions (2pi -> 0 rads)\n",
        "4. From each phase transition, use the ext-driven H & C values set the model's initiial internal state\n",
        "5. Initialize a simulation and self-drive for 200 samples\n",
        "\n"
      ],
      "metadata": {
        "id": "rVW0Xhdi8nP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(3,len(All_mod_name)):\n",
        "  # 1. make folder to store model\n",
        "  newfoldpath = path + All_mod_name[j]\n",
        "\n",
        "  # extract path to store each model and generated data\n",
        "  savepath = path + All_modelname[j]\n",
        "  mod_name = All_mod_name[j]\n",
        "  print('Working on: ' + mod_name + ' model ' + str(j) + ' / ' + str(len(All_mod_name)))\n",
        "\n",
        "  # Specify variables for model run instance\n",
        "  # Number of Units\n",
        "  numunits = All_nodes[j]\n",
        "\n",
        "  # Lookback parameter\n",
        "  lookback = All_seq[j]\n",
        "\n",
        "  # Training and Validation Set-up\n",
        "  trainseg = All_trainseg[j]\n",
        "  valseg = All_valseg[j]\n",
        "\n",
        "  # Initialize a signle figure\n",
        "  plt.figure(figsize = [50,25])\n",
        "  plotVar = 2\n",
        "\n",
        "  # Load model and set weights\n",
        "  with tf.device('/device:GPU:0'):\n",
        "      model = tf.keras.models.load_model(savepath + mod_name + '_bestwhole.h5') \n",
        "\n",
        "      # Set the trained model weights to new model to evaluate external predictions and self-driving \n",
        "      model2 = tf.keras.models.Sequential()\n",
        "      model2.add(tf.compat.v1.keras.layers.CuDNNLSTM(units = numunits, stateful=True, return_sequences=True, batch_input_shape =(1,None,feats)))\n",
        "      model2.add(tf.compat.v1.keras.layers.Dense(units=6))\n",
        "      model2.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "      # Set model 2 weights from model 1\n",
        "      for l1, l2 in zip(model.layers, model2.layers):\n",
        "        assert l1.get_config().keys()==l2.get_config().keys()\n",
        "      for key, v in l1.get_config().items():\n",
        "          if key=='name':\n",
        "              continue\n",
        "          if not v==l2.get_config()[key]:\n",
        "              print(l1.name, key, 'not matching.', 'Old,new : ', v, l2.get_config()[key], '\\n')\n",
        "\n",
        "      model2.set_weights(model.get_weights())\n",
        "      assert np.all([np.array_equal(w1, w2) for (w1,w2) in zip(model.get_weights(), model2.get_weights())]) \n",
        "\n",
        "  # 2. Load phase data\n",
        "  phs = scipy.io.loadmat(savepath + mod_name + '_PhaseVariables.mat')\n",
        "  phs = phs['PhaseVariables'] # [num trials x num samples per trial]\n",
        "\n",
        "  # 3. Load Ext Driven H & C values\n",
        "  temp = scipy.io.loadmat(savepath + mod_name + '_extdriveHCs_testset.mat')\n",
        "  temp = temp['ext_drive_sigs']\n",
        "  ExternalDriveHCs = np.reshape(temp, (trialnum,trialsamp,numunits*2))  # [num trials x num samples per trial x num-nodes-times-2]\n",
        "\n",
        "  # 4. Find initial states and corresponding H & C values\n",
        "  M = len(phs) # number of trials\n",
        "  print(M)\n",
        "  trialConcatLen = 1000; # concatentate predictions to this trial length to ensure that we evaluate the same amount of data across trials\n",
        "\n",
        "  # 5. Preallocate arrays for simulations\n",
        "  HC_self_concat = np.empty(shape=[0, numunits*2]) # Self driven sigs\n",
        "  HC_ext_concat = np.empty(shape=[0, numunits*2]) # ExternallyDrivenSigs for comparison\n",
        "  DATA_concat = np.empty(shape=[0, feats]) # Data\n",
        "  Pred_concat = np.empty(shape=[0, feats]) # Predictions\n",
        "  Predicted_KIN = np.empty(shape = [trialnum, trialsamp, feats]) # We don't simulate for the full 1500 samples, but we're OK with NaNs at the end\n",
        "  test_ind = np.arange(0, len(all_inputdata_s), 1)  # run all input data through\n",
        "  R2_muSD = np.empty(shape=[0,2]) # R-squared\n",
        "\n",
        "  # For each trial, get initial H & C values, and simulate from each initial condition\n",
        "  for mm in range(M):\n",
        "    R2 = np.empty(shape=[0]) # R-squared\n",
        "    # Holds data for each trial\n",
        "    HC_self_concat_tr = np.empty(shape=[0, numunits*2]) # Self driven sigs\n",
        "    HC_ext_concat_tr = np.empty(shape=[0, numunits*2]) # ExternallyDrivenSigs for comparison\n",
        "\n",
        "    print('Generating short-time predictions for trial: ' + str(mm+1) + ' of ' + str(len(test_ind)))\n",
        "    # Get transitions\n",
        "    transitionInds,_ = find_peaks(phs[mm], prominence = np.pi*3/2)\n",
        "    Nx = len(transitionInds)-1 # Number of initial conditions minus one\n",
        "\n",
        "    # Get initial states\n",
        "    X0 = all_inputdata_s[mm,transitionInds,:]\n",
        "\n",
        "    # Get H & C values\n",
        "    HC0 = ExternalDriveHCs[mm,transitionInds,:]\n",
        "\n",
        "    # Plot as sanity check\n",
        "    '''plt.figure()\n",
        "    plt.plot(phs[mm], label = 'Phase')\n",
        "    plt.plot(transitionInds,phs[mm][transitionInds],'*', label = 'Initial conditions')\n",
        "    plt.xlabel('Sample')\n",
        "    plt.ylabel('Phase (rad)')\n",
        "    plt.legend()\n",
        "    plt.show()'''\n",
        "\n",
        "    # Pre-allocate arrays\n",
        "    preds = np.zeros((1, trialsamp, feats))\n",
        "    hcs = np.zeros((2, trialsamp, numunits))\n",
        "    data = np.zeros((1, trialsamp, feats))\n",
        "    extD = np.zeros((1, trialsamp, numunits*2))\n",
        "\n",
        "    if Nx < 20 and Nx > 5:\n",
        "      for g in range(Nx): # For each initial state, reset model's internal state and simulate\n",
        "        with tf.device('/device:GPU:0'):\n",
        "          print('Simiulating cycle: ' + str(g+1) + ' of ' + str(Nx))\n",
        "          # Feed in externally-driven H's and C's at each initial condition\n",
        "          model2.layers[0].reset_states( [np.reshape(HC0[g,0:numunits], (1,numunits)), np.reshape(HC0[g,numunits:], (1,numunits))] )          \n",
        "\n",
        "          # Integrate\n",
        "          sampleWindow = transitionInds[g+1] - transitionInds[g] # prediction length\n",
        "          windowInds = range(transitionInds[g], transitionInds[g+1]) # prediction horizon - integrate for this many samples\n",
        "          for i in tqdm(windowInds):\n",
        "              data[:,i,:] = all_inputdata_s[mm,i,:]\n",
        "              extD[:,i,:] = ExternalDriveHCs_3[mm,i,:]\n",
        "              if i == transitionInds[g]:\n",
        "                  preds[:,i,:] = all_inputdata_s[mm,i,:][None,None,:] # Initialize the simulation\n",
        "              else:\n",
        "                  preds[:,i,:] = model2.predict_step(preds[0,i-1,:][None,None,:]) # Integrate forward in time\n",
        "\n",
        "              # Extract internal states\n",
        "              hcs[:,i,:] = np.array(model2.layers[0].states)[:,0]\n",
        "              Hvalues = hcs[0][windowInds,:]\n",
        "              Cvalues = np.tanh(hcs[1][windowInds,:])\n",
        "              HC_self = np.concatenate((Hvalues, Cvalues), axis=1) # concatenate Hs and Cs of single trial\n",
        "\n",
        "          # concatenate trials\n",
        "          HC_ext_concat_tr = np.append(HC_ext_concat_tr, extD[0,windowInds,:], axis = 0) # Internal states\n",
        "          HC_self_concat_tr = np.append(HC_self_concat_tr, HC_self, axis = 0) # Internal states\n",
        "          DATA_concat = np.append(DATA_concat, data[0][windowInds,:], axis = 0) # Data\n",
        "          Pred_concat = np.append(Pred_concat, preds[0][windowInds,:], axis = 0) # Predictions\n",
        "\n",
        "          # Compute prediction accuracy across trials\n",
        "          fullInds = range(transitionInds[0], transitionInds[-1])\n",
        "          X = np.reshape(data[0][fullInds,:],(-1,1))\n",
        "          X_hat = np.reshape(preds[0][fullInds,:],(-1,1))\n",
        "          num = np.sum((X-X_hat)**2)\n",
        "          den = np.sum((X-np.mean(X))**2)\n",
        "          # Compute and store R-squared value\n",
        "          R2 = np.append(R2,[1-num/den], axis = 0)\n",
        "\n",
        "      # Store predicted internal states\n",
        "      HC_ext_concat = np.append(HC_ext_concat, HC_ext_concat_tr[0:trialConcatLen,:], axis = 0) # Extenrally-driven\n",
        "      HC_self_concat = np.append(HC_self_concat, HC_self_concat_tr[0:trialConcatLen,:], axis = 0) # Self-driven\n",
        "\n",
        "      # Plot data and predictions for each trial\n",
        "      plt.subplot(8,9,mm+1)\n",
        "      plt.plot(all_inputdata_s[mm,:,plotVar], label = 'data')\n",
        "      plt.plot(preds[0,:,plotVar], label = 'prediction')    \n",
        "      plt.title('Trial' + str(mm+1))\n",
        "      if (mm+1) % 9 == 1:\n",
        "        plt.ylabel('Joint angle (deg)')\n",
        "      if mm > 62:\n",
        "        plt.xlabel('Sample')      \n",
        "      if mm == 0:\n",
        "        plt.legend()\n",
        "\n",
        "    else: # Case where we identify too many or too few trials. Provide a trivial R-squared value that we conver to NaN during analysis\n",
        "      \n",
        "      print('Failure! Trial ' + str(mm+1))\n",
        "      data[:,:,:] = all_inputdata_s[mm,:,:]\n",
        "      extD = np.zeros((trialConcatLen, 2*numunits)) # concatenate Hs and Cs of single trial\n",
        "      HC_ext_concat = np.append(HC_ext_concat, extD, axis = 0) # concatenate trials\n",
        "      HC_self = np.zeros((trialConcatLen, 2*numunits)) # concatenate Hs and Cs of single trial\n",
        "      HC_self_concat = np.append(HC_self_concat, HC_self, axis = 0) # concatenate trials\n",
        "      DATA_concat = np.append(DATA_concat, data[0], axis = 0) # Data\n",
        "      R2 = 0.001*np.array([1,1,1,1,1])\n",
        "    \n",
        "    # Store average and SD of R2\n",
        "    aa = np.array([np.mean(R2), np.std(R2)])\n",
        "    R2_muSD = np.append(R2_muSD, aa[np.newaxis,:], axis = 0)\n",
        "\n",
        "  # Same figure\n",
        "  plt.savefig(savepath + mod_name + 'selfDriveVsData.png', dpi = 150)\n",
        "  plt.show()   \n",
        "    \n",
        "\n",
        "  # Save resulting HCs and R2 corresponding to kinematics predictions\n",
        "  scipy.io.savemat(savepath + mod_name + '_selfExtDriveHC_shortTime.mat', {'HC_self_concat': HC_self_concat, 'HC_ext_concat': HC_ext_concat, 'R2_muSD': R2_muSD})\n"
      ],
      "metadata": {
        "id": "Pvq0jMM589pU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}