{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bermanlabemory/gait_signatures/blob/main/Gait_Signatures_Script_6_Compare_Gait_Signature_Alignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This script compares gait signature alignment between different models. \n",
        "\n",
        "This is just a sample script to load and compute means/SD's of the alignment results\n",
        "____________\n",
        "____________\n",
        "**NOTE**: This file was ONLY used to select model hyperparameters and generate supplementary figures.\n",
        "\n",
        "First, Scripts 1-5 must be run to generate the models that are analyzed here.\n",
        "\n",
        "____________\n",
        "____________\n",
        "**Steps:** \n",
        "1. General setup: load gait signature alignment for each model.\n",
        "2. Compute the average/SD across subjects for each initialization (random initial RNN parameters during model fitting).\n",
        "3. If multiple model initializations have been run, perform independent-samples t-tests to compare between model pairs. Samples correspond to each initialization\n",
        "   4. Alternatively, you could run paired t-tests to compare across models with only 1 initializations each\n",
        "____________\n",
        "Gait signature alignment results are stored in a [subject x run x model] array\n",
        "____________\n",
        "\n",
        "**Created by**: Michael C. Rosenberg\n",
        "\n",
        "**Date**: 11/11/22"
      ],
      "metadata": {
        "id": "onLC9Msr6_RX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 0**: Mount (connect to) your google drive folder where you want to save the simulation results and model parameters."
      ],
      "metadata": {
        "id": "kLBAyLXe7udu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "Iuzkec-P1z7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d291434-8c3a-44b5-f0ff-0ba3bc55e7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check python version \n",
        "from platform import python_version\n",
        "\n",
        "print(python_version())\n",
        "\n",
        "# check tensorflow version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# GPU/ram\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "TfiYeSIR702R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9f0fbe-4906-4659-e473-12b720db4135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8.15\n",
            "2.9.2\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1**: Import necessary packages and functions to develop model"
      ],
      "metadata": {
        "id": "WDY0A5Qa77-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# from keras.layers.recurrent import LSTM # Deprecated :(\n",
        "from tensorflow.python.keras.layers.recurrent import LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.model_selection as model_selection\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import keras as k\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from copy import copy\n",
        "import scipy.io\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "from scipy import interpolate\n",
        "from scipy.special import iv\n",
        "from numpy import sin,cos,pi,array,linspace,cumsum,asarray,dot,ones\n",
        "from pylab import plot, legend, axis, show, randint, randn, std,lstsq\n",
        "\n",
        "from sklearn.manifold import MDS\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm "
      ],
      "metadata": {
        "id": "Sjnyu-Hi70_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions\n",
        "%cd /content/drive/My Drive/NeuromechanicsLab/GaitSignatures/\n",
        "\n",
        "# Ensure fourierseries.py is in the pathway\n",
        "!ls -l fourierseries.py\n",
        "\n",
        "import fourierseries\n",
        "import util\n",
        "import phaser\n",
        "import dataloader\n",
        "# Preprocess data for a single subject - to be send to modeling frameworks\n",
        "def find_phase(k):\n",
        "    \"\"\"\n",
        "    Detrend and compute the phase estimate using Phaser\n",
        "    INPUT:\n",
        "      k -- dataframe\n",
        "    OUTPUT:\n",
        "      k -- dataframe\n",
        "    \"\"\"\n",
        "    #l = ['hip_flexion_l','hip_flexion_r'] # Phase variables = hip flexion angles\n",
        "    y = np.array(k)\n",
        "    print(y.shape)\n",
        "    y = util.detrend(y.T).T\n",
        "    print(y.shape)\n",
        "    phsr = phaser.Phaser(y=y)\n",
        "    k[:] = phsr.phaserEval(y)[0,:]\n",
        "    return k\n",
        "\n",
        "# Interpolation function\n",
        "def vonMies(t,t_0, b):\n",
        "    out = np.exp(b*np.cos(t-t_0))/(2*pi*iv(0, b))\n",
        "    return out"
      ],
      "metadata": {
        "id": "956M3pr8_56k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd921599-c337-4baa-b3e6-08a50ab71ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/NeuromechanicsLab/GaitSignatures\n",
            "-rw------- 1 root root 7259 May 29  2020 fourierseries.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/NeuromechanicsLab/GaitSignatures/phaser.py:282: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if len( set( [ ele.shape[0] for ele in y ] ) ) is not 1:\n",
            "/content/drive/My Drive/NeuromechanicsLab/GaitSignatures/phaser.py:413: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if len( idx ) is 0:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Load module in Google Drive"
      ],
      "metadata": {
        "id": "g4J5BZIg8EYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The path to save the models and read data from\n",
        "path = '/content/drive/My Drive/NeuromechanicsLab/GaitSignatures/'\n",
        "\n",
        "# Insert the directory\n",
        "import sys\n",
        "sys.path.insert(0,path)"
      ],
      "metadata": {
        "id": "8PRNNDCI71CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3**: Load in data and specify variables/parameters"
      ],
      "metadata": {
        "id": "DAhc9QkW8ONR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-changing variables \n",
        "\n",
        "# number of trials in dataset \n",
        "trialnum = 72 # 72 total trials\n",
        "\n",
        "# number of samples in each trial\n",
        "trialsamp = 1500\n",
        "\n",
        "# number of features collected per trial\n",
        "feats = 6\n",
        "\n",
        "#Batch size - same as the number of traintrials\n",
        "batch_size = trialnum\n",
        "\n",
        "# Number of Layers\n",
        "numlayers = 1\n",
        "\n",
        "# Choose the number of iterations to train the model- if this script has been run previously enter a value greater than was \n",
        "# inputted before and rerun the script. \n",
        "finalepoch = 10000\n",
        "\n",
        "# load the input data/kinematics\n",
        "datafilepath = path + 'PareticvsNonP_RNNData.csv' #input data\n",
        "all_csvnp = np.loadtxt(datafilepath,delimiter=',').T\n",
        "\n",
        "# reshape all the input data into a tensor\n",
        "all_inputdata_s = all_csvnp.reshape(trialnum,trialsamp,feats) \n",
        "csvnp = all_inputdata_s\n",
        "print('original input data shape is: '+ str(all_csvnp.shape ))\n",
        "print('input data reshaped is: '+ str(all_inputdata_s.shape))"
      ],
      "metadata": {
        "id": "fXEEUgWB8Mk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d926fbf-6f75-4ddf-d3bb-ede4bcab7d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original input data shape is: (108000, 6)\n",
            "input data reshaped is: (72, 1500, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4**: Develop list of model architectures and corresponding variables to train. This step also generates list of folder names and pathways where the models will be saved and accessed later."
      ],
      "metadata": {
        "id": "q_A7pitQ8XS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a list of models and corresponding parameters to test \n",
        "test_model_nodes = [128,256,512,1024] \n",
        "seqs = [249,499,749] #lookback parameter\n",
        "\n",
        "test_model_nodes = [ 512] \n",
        "seqs = [499] #lookback parameter\n",
        "\n",
        "# run multiple model architechtures many times to test stability of cost function outputs\n",
        "runs = 1 # Number of times to train recurrent neural network (RNN) models, starting from random initial conditions. We used this for hyperparameter selection\n",
        "test_model_seq = np.repeat(seqs, runs) # Specify each model's hyperparameters\n",
        "\n",
        "count = np.arange(runs)\n",
        "\n",
        "All_nodes = np.empty([0,1], dtype='int')\n",
        "All_seq = np.empty([0,1],dtype='int')\n",
        "All_valseg = np.empty([0,1],dtype='int')\n",
        "All_trainseg = np.empty([0,1],dtype='int')\n",
        "All_modelname = []\n",
        "All_mod_name = []\n",
        "count = np.empty([0,1],dtype='int'); #initialize model run -- this serves as the model run ID number\n",
        "ct = 0\n",
        "for a in test_model_nodes:\n",
        "  for b in test_model_seq:\n",
        "    count = np.append(count,  ct + 1 )\n",
        "    #if statement for valseg, trainseg based on sequence length\n",
        "    if int(b) == 249:\n",
        "      trainseg = 4\n",
        "      valseg = 2\n",
        "    elif int(b) == 499: \n",
        "      trainseg = 2\n",
        "      valseg = 1\n",
        "    elif int(b) == 749:\n",
        "      trainseg = 1\n",
        "      valseg = 1\n",
        "\n",
        "    # Store resulting model structures and training plans\n",
        "    All_nodes = np.append(All_nodes, a) \n",
        "    All_seq = np.append(All_seq, int(b))\n",
        "    All_valseg = np.append(All_valseg, valseg)\n",
        "    All_trainseg = np.append(All_trainseg, trainseg)\n",
        "    All_modelname = np.append(All_modelname, 'UNIT_' + str(a) + '_LB_' + str(b) + '_run_' + str(count[-1]) + '/' )\n",
        "    All_mod_name = np.append(All_mod_name, 'UNIT_' + str(a) + '_LB_' + str(b) + '_run_' + str(count[-1]) )\n",
        "\n",
        "    if ct+1 < runs:\n",
        "      ct += 1\n",
        "    else:\n",
        "      ct = 0"
      ],
      "metadata": {
        "id": "vAN8l21V8ZeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7caefb63-5a11-469e-b21b-72ba4bf50adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "['UNIT_256_LB_499_run_1' 'UNIT_256_LB_499_run_2' 'UNIT_256_LB_499_run_3'\n",
            " 'UNIT_256_LB_499_run_4' 'UNIT_256_LB_499_run_5' 'UNIT_256_LB_499_run_6'\n",
            " 'UNIT_256_LB_499_run_7' 'UNIT_256_LB_499_run_8' 'UNIT_256_LB_499_run_9'\n",
            " 'UNIT_256_LB_499_run_10' 'UNIT_256_LB_749_run_1' 'UNIT_256_LB_749_run_2'\n",
            " 'UNIT_256_LB_749_run_3' 'UNIT_256_LB_749_run_4' 'UNIT_256_LB_749_run_5'\n",
            " 'UNIT_256_LB_749_run_6' 'UNIT_256_LB_749_run_7' 'UNIT_256_LB_749_run_8'\n",
            " 'UNIT_256_LB_749_run_9' 'UNIT_256_LB_749_run_10' 'UNIT_512_LB_499_run_1'\n",
            " 'UNIT_512_LB_499_run_2' 'UNIT_512_LB_499_run_3' 'UNIT_512_LB_499_run_4'\n",
            " 'UNIT_512_LB_499_run_5' 'UNIT_512_LB_499_run_6' 'UNIT_512_LB_499_run_7'\n",
            " 'UNIT_512_LB_499_run_8' 'UNIT_512_LB_499_run_9' 'UNIT_512_LB_499_run_10']\n",
            "/content/drive/My Drive/NeuromechanicsLab/GaitSignatures/UNIT_256_LB_499_run_1/UNIT_256_LB_499_run_1_bestwhole.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load short-time gait signature alignment"
      ],
      "metadata": {
        "id": "rVW0Xhdi8nP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-allocate arrays\n",
        "ST = np.zeros((trialnum,runs,3)) # [subject x runs x models]\n",
        "R2_ST = np.zeros((trialnum,runs,3)) # [subject x runs x models]\n",
        "\n",
        "for j in range(len(All_mod_name)):\n",
        "  # extract path to store each model and generated data\n",
        "  savepath = path + All_modelname[j]\n",
        "  mod_name = All_mod_name[j]\n",
        "\n",
        "  # Load results\n",
        "  temp = scipy.io.loadmat(savepath + mod_name + '_shortTimeAlignment.mat')\n",
        "  # Load Euclidean distance alignment to identify bogus trials\n",
        "  EuclidAlignment = temp['EuclideanAlignment']\n",
        "  ST[:,j % 10, int(np.ceil((j+1)/10))-1] = ShortTimeAlignment[:,0]\n",
        "\n",
        "  # Extract alignment results\n",
        "  R2 = temp['R2']\n",
        "  R2_ST[:,j % 10, int(np.ceil((j+1)/10))-1] = R2[:,0]\n",
        "\n",
        "# Remove any short-time sigs where clean cycles were not identified\n",
        "badInds, temp =  np.where(np.any(ST == 0, axis = 1)) \n",
        "ST = np.delete(ST, np.unique(badInds), 0)\n",
        "R2_ST = np.delete(R2_ST, np.unique(badInds), 0)\n",
        "\n",
        "\n",
        "# Examples:\n",
        "# Average across subjects\n",
        "R2_ST_mu = np.mean(R2_ST, axis = 0)\n",
        "R2_ST_sd = np.std(R2_ST, axis = 0)"
      ],
      "metadata": {
        "id": "E2UNrdO2Ziw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Long-time gait signature alignment"
      ],
      "metadata": {
        "id": "nmYw15Hc0DGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-allocate arrays\n",
        "LT = np.zeros((trialnum,runs,3)) # [subject x runs x models]\n",
        "R2_LT = np.zeros((trialnum,runs,3)) # [subject x runs x models]\n",
        "print(np.shape(LT))\n",
        "\n",
        "for j in range(len(All_mod_name)):\n",
        "  savepath = path + All_modelname[j]\n",
        "  mod_name = All_mod_name[j]\n",
        "\n",
        "  # Load long-time alignment results\n",
        "  temp = scipy.io.loadmat(savepath + mod_name + '_LongTimeAligment.mat')\n",
        "  # Extract R-squared\n",
        "  R2 = temp['R2']\n",
        "  R2_LT[:,j % 10, int(np.ceil((j+1)/10))-1] = R2[:,0]\n",
        "\n",
        "# Remove bad trials (same trials as short-time alignment)\n",
        "R2_LT = np.delete(R2_LT, np.unique(badInds), 0)\n",
        "\n",
        "# Examples:\n",
        "# Average across subjects\n",
        "R2_LT_mu = np.mean(R2_LT, axis = 0)\n",
        "R2_LT_sd = np.std(R2_LT, axis = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JVaIeZmtQFc",
        "outputId": "b3ed1abb-948d-4b06-8ab8-a953a9b3473d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 10, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate a scatter plot with short- and long-time gait signature alignment on the horizontal and vertical axes, respectively\n",
        "\n",
        "Plot each initialization's mean, plus the mean and SD across all initializations for each hyperparameter pair. This is just like what we did for training/validation loss\n",
        "\n",
        "**NOTE**: R-squared is a better metric because it is invariant to sample size for large samples (converges to a final value)"
      ],
      "metadata": {
        "id": "Sn_HPluRoMMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clr = ['r','g','b']\n",
        "\n",
        "# R-squared - mean\n",
        "plt.figure()\n",
        "# Plot each run and average/SD\n",
        "for jj in range(3): # Each model\n",
        "  plt.plot(R2_ST_mu[:,jj], R2_LT_mu[:,jj],'.', color = clr[jj])\n",
        "\n",
        "# Format\n",
        "plt.xlabel('Short-time R^2')\n",
        "plt.ylabel('Long-time R^2')\n",
        "\n",
        "# Plot each average/SD\n",
        "for jj in range(3): # Each model\n",
        "  plt.plot(np.mean(R2_ST_mu[:,jj]), np.mean(R2_LT_mu[:,jj]), '.', markersize = 20, color = clr[jj])\n",
        "  plt.plot(np.mean(R2_ST_mu[:,jj])+[np.std(R2_ST_mu[:,jj]),-np.std(R2_ST_mu[:,jj])], [np.mean(R2_LT_mu[:,jj]), np.mean(R2_LT_mu[:,jj])], color = clr[jj])\n",
        "  plt.plot([np.mean(R2_ST_mu[:,jj]), np.mean(R2_ST_mu[:,jj])], np.mean(R2_LT_mu[:,jj])+[np.std(R2_LT_mu[:,jj]),-np.std(R2_LT_mu[:,jj])], color = clr[jj])\n",
        "\n",
        "plt.legend(['256-499','256-749','512-499'])\n",
        "plt.title('R-squared - Mean-SD')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lDdZP-YdoNy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run *unpaired* t-tests across between between each pair of the 3 models. Report p-values for each test. This tells us if the models are different given variability due to intialization."
      ],
      "metadata": {
        "id": "G5UauvgSqUWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Pre-allocate arrays\n",
        "p_ST = np.zeros((3,3))\n",
        "p_LT = np.zeros((3,3))\n",
        "\n",
        "# Run ttests\n",
        "for ii in range(3):\n",
        "  for jj in range(3):\n",
        "    if ii < jj:\n",
        "      t,p_ST[ii,jj] = scipy.stats.ttest_ind(p_ST[:,ii], p_ST[:,jj])\n",
        "      t,p_LT[ii,jj] = scipy.stats.ttest_ind(p_LT[:,ii], p_LT[:,jj])\n",
        "\n",
        "print(p_ST)\n",
        "print(p_LT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdP-sgYAqLDj",
        "outputId": "de98a0f1-9576-4704-979d-8c72c086614d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.65548847 0.16834751]\n",
            " [0.         0.         0.00285636]\n",
            " [0.         0.         0.        ]]\n",
            "[[0.         0.44430576 0.01353344]\n",
            " [0.         0.         0.0177207 ]\n",
            " [0.         0.         0.        ]]\n",
            " \n",
            "[[0.00000000e+00 5.13817955e-01 5.53110419e-02]\n",
            " [0.00000000e+00 0.00000000e+00 3.94825364e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
            "[[0.00000000e+00 5.70132173e-01 2.39995186e-04]\n",
            " [0.00000000e+00 0.00000000e+00 3.69378869e-07]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ]
        }
      ]
    }
  ]
}